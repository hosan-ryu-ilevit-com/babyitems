// Supabase ë°ì´í„°ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
import { createClient } from '@supabase/supabase-js';
import * as fs from 'fs';
import * as path from 'path';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!;

const supabase = createClient(supabaseUrl, supabaseKey);

interface DailyLog {
  id: number;
  date: string;
  events: any[];
  created_at?: string;
}

async function exportLogs() {
  console.log('ğŸš€ Starting log export...');

  const BATCH_SIZE = 10; // í•œ ë²ˆì— 10ê°œì”©ë§Œ ê°€ì ¸ì˜¤ê¸°
  const OUTPUT_DIR = path.join(__dirname, '../data/backup');

  // ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
  if (!fs.existsSync(OUTPUT_DIR)) {
    fs.mkdirSync(OUTPUT_DIR, { recursive: true });
  }

  try {
    // 1. ì „ì²´ ë‚ ì§œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ê°€ë²¼ìš´ ì¿¼ë¦¬)
    console.log('ğŸ“… Fetching all dates...');
    const { data: dates, error: datesError } = await supabase
      .from('daily_logs')
      .select('date')
      .order('date', { ascending: false });

    if (datesError) {
      console.error('âŒ Failed to fetch dates:', datesError);
      return;
    }

    console.log(`âœ… Found ${dates?.length || 0} dates`);

    if (!dates || dates.length === 0) {
      console.log('No data to export');
      return;
    }

    // 2. ë‚ ì§œë³„ë¡œ ë°ì´í„° ì¶”ì¶œ (í•˜ë‚˜ì”©)
    const allLogs: DailyLog[] = [];
    let successCount = 0;
    let errorCount = 0;

    for (let i = 0; i < dates.length; i++) {
      const date = dates[i].date;
      console.log(`\nğŸ“¦ [${i + 1}/${dates.length}] Fetching logs for ${date}...`);

      try {
        const { data: log, error: logError } = await supabase
          .from('daily_logs')
          .select('*')
          .eq('date', date)
          .single();

        if (logError) {
          console.error(`  âŒ Failed: ${logError.message}`);
          errorCount++;

          // ê°œë³„ íŒŒì¼ë¡œ ì—ëŸ¬ ë¡œê·¸ ì €ì¥
          fs.writeFileSync(
            path.join(OUTPUT_DIR, `error_${date}.json`),
            JSON.stringify({ date, error: logError }, null, 2)
          );

          continue;
        }

        if (log) {
          allLogs.push(log);
          successCount++;

          // ê°œë³„ íŒŒì¼ë¡œë„ ì €ì¥ (ì•ˆì „)
          fs.writeFileSync(
            path.join(OUTPUT_DIR, `log_${date}.json`),
            JSON.stringify(log, null, 2)
          );

          console.log(`  âœ… Success: ${log.events?.length || 0} events`);
        }

        // API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)
        await new Promise(resolve => setTimeout(resolve, 1000));
      } catch (error) {
        console.error(`  âŒ Unexpected error:`, error);
        errorCount++;
      }
    }

    // 3. ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ì €ì¥
    const outputFile = path.join(OUTPUT_DIR, 'all_logs.json');
    fs.writeFileSync(outputFile, JSON.stringify(allLogs, null, 2));

    console.log('\nâœ… Export completed!');
    console.log(`  ğŸ“ Output directory: ${OUTPUT_DIR}`);
    console.log(`  âœ… Success: ${successCount} dates`);
    console.log(`  âŒ Failed: ${errorCount} dates`);
    console.log(`  ğŸ“„ Total file: ${outputFile}`);
    console.log(`  ğŸ“„ Individual files: ${successCount} files`);

    // í†µê³„ ì¶œë ¥
    const totalEvents = allLogs.reduce((sum, log) => sum + (log.events?.length || 0), 0);
    console.log(`\nğŸ“Š Statistics:`);
    console.log(`  Total dates: ${allLogs.length}`);
    console.log(`  Total events: ${totalEvents}`);

    return allLogs;
  } catch (error) {
    console.error('âŒ Fatal error:', error);
    throw error;
  }
}

// ì‹¤í–‰
exportLogs()
  .then(() => {
    console.log('\nâœ¨ Done!');
    process.exit(0);
  })
  .catch((error) => {
    console.error('\nğŸ’¥ Failed:', error);
    process.exit(1);
  });
